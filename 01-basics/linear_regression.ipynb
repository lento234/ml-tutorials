{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lento234/ml-tutorials/blob/main/01-basics/linear_regression.ipynb)\n",
    "\n",
    "**References**:\n",
    "- https://pytorch.org/\n",
    "- https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/linear_regression/main.py\n",
    "- https://en.wikipedia.org/wiki/Linear_regression\n",
    "- https://en.wikipedia.org/wiki/Backpropagation\n",
    "- https://en.wikipedia.org/wiki/Stochastic_gradient_descent\n",
    "\n",
    "\n",
    "\n",
    "**Linear regression**\n",
    "\n",
    "Given a data set $\\{y_i, x_i\\}_{i=1}^n$ of $n$ statistical units, we have the following relationship:\n",
    "\n",
    "$$ y_i = \\beta_1 x_i + \\beta_0 + \\varepsilon_i, \\qquad i=1,\\ldots, n,$$\n",
    "\n",
    "where:\n",
    "- $y_i$ is observed value (dependent variable\n",
    "- $x_i$ is the independent variable\n",
    "- $\\beta_1$ and $\\beta_0$ are the trainable parameters\n",
    "- $\\varepsilon_i$ is the measurement error\n",
    "\n",
    "**Table of Content**\n",
    "1. [Setup environment](#setup)\n",
    "2. [Define the model, loss function and optimizer](#model)\n",
    "3. [Train the model](#train)\n",
    "4. [Predict and evaluate the model](#evaluate)\n",
    "5. [Save the trained model](#save)\n",
    "6. [Load pretrained model](#load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages / modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.style.use('seaborn-poster')\n",
    "mpl.rcParams['mathtext.fontset'] = 'cm'\n",
    "mpl.rcParams['figure.figsize'] = 5 * np.array([1.618033988749895, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducability\n",
    "seed = 234\n",
    "np.random.seed(seed)\n",
    "torch.random.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "beta_1 = 2.0\n",
    "beta_0 = 0.3\n",
    "eps_std = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.rand(n,1)\n",
    "eps = np.random.normal(scale=eps_std, size=(n,1))\n",
    "y_train = x_train*beta_1 + beta_0 + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_train, y_train, 'k.', label='observations')\n",
    "ax.plot(x_train, x_train*beta_1 + beta_0, 'tab:gray',\n",
    "        label=r'analytical ($\\beta_1={:.2f}$, $\\beta_0={:.2f}$)'.format(beta_1, beta_0))\n",
    "ax.set(xlabel='$x$', ylabel='$y$', xlim=(0,1), ylim=(0.1, 2.4));\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 2. Define the model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1 # number of nodes (1 weight + 1 bias)\n",
    "num_epochs = 60 # i.e. number of iterations\n",
    "learning_rate = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "$$ \\mathcal{F}: x \\rightarrow y $$\n",
    "\n",
    "**Linear 1-D model**:\n",
    "\n",
    "$$ \\mathcal{F}(x) = \\hat{y} = x a + b$$\n",
    "where:\n",
    "- $y$ is the ground truth\n",
    "- $\\hat{y}$ is the predicted output\n",
    "- $a$ is the learnable weight, i.e. $a \\equiv \\beta_1$\n",
    "- $b$ is the learnable bias, i.e. $b \\equiv \\beta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "model = nn.Linear(in_features=n_features, out_features=n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "**$L^1$-norm:**\n",
    "\n",
    "$$ \\mathcal{L}(X, Y) = \\textrm{mean} \\left( \\{l_1,\\dots,l_N\\}^\\top \\right), \\quad l_n = \\left| \\hat{y}_n - y_n \\right| $$\n",
    "where:\n",
    "- $X \\in \\mathbb{R}^N$ is the input matrix\n",
    "- $Y \\in \\mathbb{R}^N$ is the ground truth matrix\n",
    "- $N$ is the batch size (for now, batch size = number of examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.L1Loss() # L^1-norm, aka. mean absolute error loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "**Stochastic gradient descent**\n",
    "\n",
    "$$ \\theta_{n+1} = \\theta_n - \\eta \\nabla \\mathcal{L}(\\theta_n) $$\n",
    "\n",
    "where:\n",
    "- $\\theta$ are the trainable parameters\n",
    "- $\\eta$ is the learning rate (i.e. step size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # Stochastic gradient-descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## 3. Train the model\n",
    "\n",
    "$$ \\mathcal{F}^* = \\arg \\min_{\\mathcal{F}}\\ \\mathcal{L}(X, Y)$$\n",
    "\n",
    "**Algorithm:**\n",
    "1. Convert data to torch tensor: `torch.from_numpy(...)`\n",
    "2. Forward pass: `y_pred = model(x)`\n",
    "3. Calculate loss: `loss = criterion(y_pred, y)`\n",
    "4. Compute gradients: `loss.backward()`\n",
    "5. Update weights: `optimizer.step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "for epoch in range(num_epochs):\n",
    "    # 1. Convert numpy arrays to torch tensors\n",
    "    x = torch.from_numpy(x_train.astype('float32'))\n",
    "    y = torch.from_numpy(y_train.astype('float32'))\n",
    "\n",
    "    # 2. Forward pass\n",
    "    y_pred = model(x) # prediction step\n",
    "    \n",
    "    # 3. Calculate loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    # 4. Backward propagation \n",
    "    optimizer.zero_grad() # reset gradients to zero\n",
    "    loss.backward() # backprop: calculate gradients w.r.t to loss\n",
    "    \n",
    "    # 5. Update weights\n",
    "    optimizer.step() # update gradient\n",
    "    \n",
    "    loss_history.append(loss.item())\n",
    "    if (epoch % 10) == 0 or epoch==(num_epochs-1):\n",
    "        print ('[Epoch {}]: loss = {:.4f}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(loss_history, '.-')\n",
    "ax.set(xlabel='epoch', ylabel='MSE loss',\n",
    "       title='Training loss history');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate\"></a>\n",
    "## 4. Predict and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predict = model(torch.from_numpy(x_train.astype('float32'))).detach().numpy()\n",
    "parameters = [param.detach().item() for param in model.parameters()]\n",
    "\n",
    "# Plot the graph\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_train, y_train, 'k.', label='observations')\n",
    "ax.plot(x_train, x_train*beta_1 + beta_0, 'tab:gray',\n",
    "        label=r'analytical: ($\\beta_1={:.2f}$, $\\beta_0={:.2f}$)'.format(beta_1, beta_0))\n",
    "ax.plot(x_train, predict, 'tab:red', \n",
    "        label=r'predicted: ($\\beta_1={:.2f}$, $\\beta_0={:.2f}$)'.format(*parameters))\n",
    "ax.set(xlabel='$x$', ylabel='$y$',\n",
    "       title='Training accuracy',\n",
    "      xlim=(0,1), ylim=(0.1, 2.4));\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "## 5. Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 6. Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model.ckpt')\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
