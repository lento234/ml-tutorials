{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10: Training a classifer with **PyTorch-lightning**\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lento234/ml-tutorials/blob/main/01-basics/03-CIFAR10_pl.ipynb)\n",
    "\n",
    "**References**:\n",
    "- https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "- https://pytorch-lightning.rtfd.io/en/latest/\n",
    "\n",
    "\n",
    "**Runtime setup: GPU accelerator at Google colab:**\n",
    "\n",
    "1. On the main menu, click **Runtime** and select **Change runtime type**. \n",
    "2. Select **GPU** as the hardware accelerator.\n",
    "\n",
    "![steps](../images/steps.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of content**\n",
    "\n",
    "1. [Load and pre-process the dataset](#load)\n",
    "2. [Define the CNN model **+ training step + loss + optimizer**](#define)\n",
    "3. [Setup the **trainer**](#trainer)\n",
    "4. [Train **and validate** the model on **train** and **test** dataset](#train)\n",
    "5. [Assess training with **tensorboard**](#tensorboard)\n",
    "6. [Test the model](#validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR10 Dataset**\n",
    "\n",
    "The dataset consists of `3x32x32` images of 10 difference classes:\n",
    "\n",
    "    airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck.\n",
    "\n",
    "![cifar10](../images/cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Lightning is easy to install. Simply ```pip install pytorch-lightning```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.style.use('seaborn-poster')\n",
    "mpl.rcParams['mathtext.fontset'] = 'cm'\n",
    "mpl.rcParams['figure.figsize'] = 5 * np.array([1.618033988749895, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 4\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load'></a>\n",
    "## 1. Load and pre-process data\n",
    "\n",
    "- Define preprocessing algorithm\n",
    "- Load training and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define preprocessing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert data to pytorch tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # normalize dataset for each channel\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download train and test dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                 download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, \n",
    "                                 download=True, transform=transform)\n",
    "\n",
    "# Dataset sampler (shuffle, distributed loading)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, \n",
    "                                          shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(f\"num. examples: train = {len(train_dataset)}, test = {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['plane', 'car', 'bird', 'cat', 'deer',\n",
    "                    'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(images, labels):    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        img = images[i] / 2 + 0.5 # unnormalize\n",
    "        plt.imshow(np.transpose(img.numpy(), (1, 2, 0)), cmap=plt.cm.binary)\n",
    "        plt.xlabel(classes[labels[i]])\n",
    "    plt.show()\n",
    "    \n",
    "# get some random training images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# show images\n",
    "imshow(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=define></a>\n",
    "## 2. Define the CNN model **+ training step + loss + optimizer**\n",
    "\n",
    "![network_architecture](../images/network_architecture.png)\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "- Input: An image of `n_channels=3`.\n",
    "- Two layer stacks of 2D convolutional layers (`Conv2d` with `kernel_size=5`) with rectified linear activation (`ReLU`) followed by a  2D max pooling (`MaxPool2D` with `kernel_size=2` and `stride=2`)\n",
    "- Three layer stacks of Fully-connected layers (`Linear`) with ReLU activaton.\n",
    "- Output: 10-dimensional vector defining the activation of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # save hyper-parameters\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.example_input_array = torch.ones(1, self.hparams.num_channels, 32, 32)\n",
    "        \n",
    "        # Define network\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(self.hparams.num_channels, 6, kernel_size=5),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 =  nn.Sequential(nn.Conv2d(6, 16, kernel_size=5),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(nn.Flatten(),\n",
    "                                    nn.Linear(16 * 5 * 5, 120),\n",
    "                                    nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(nn.Linear(120, 84),\n",
    "                                    nn.ReLU())\n",
    "        self.layer5 = nn.Linear(84, self.hparams.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_train, y_train = batch\n",
    "        y_pred = self(x_train)\n",
    "        loss = F.cross_entropy(y_pred, y_train)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True) # logging\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_test, y_test = batch\n",
    "        y_pred = self(x_test)\n",
    "        loss = F.cross_entropy(y_pred, y_test)\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x_test, y_test = batch\n",
    "        y_pred = self(x_test)\n",
    "        loss = F.cross_entropy(y_pred, y_test)\n",
    "        self.log('test_loss', loss)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(),\n",
    "                               lr=self.hparams.learning_rate,\n",
    "                               momentum=self.hparams.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "model = Net(\n",
    "    num_channels=3,\n",
    "    num_classes=num_classes,\n",
    "    learning_rate=learning_rate,\n",
    "    momentum=momentum\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=trainer></a>\n",
    "## 3. Setup the **trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU trainer\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=num_epochs,\n",
    "    progress_bar_refresh_rate=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional flags:**\n",
    "```python\n",
    "            log_gpu_memory='all', # gpu stats\n",
    "            profiler=True, # profiling stats\n",
    "            precision=16, # half-precision\n",
    "            deterministic=True # reproducability\n",
    "            accelerator='ddp' # distributed data parallelism\n",
    "            benchmark=True # cudnn benchmark and optimizing\n",
    "            callbacks=[custom_callback_one(), custom_callback_two()]\n",
    "            fast_dev_run=True # dev run for debugging all the hooks\n",
    "```\n",
    "More info: https://pytorch-lightning.readthedocs.io/en/stable/trainer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=train></a>\n",
    "## 4. Train **and validate** the model on **train** and **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=tensorboard></a>\n",
    "## 5. Assess training with **tensorboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=validate></a>\n",
    "## 6. Test the model on **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=bonus></a>\n",
    "## 7. **Bonus**: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Add a logging for training / validation `accuracy`\n",
    "\n",
    "\n",
    "See previous example (**section 5.2**)\n",
    "\n",
    "$$ \\mathrm{Accuracy} = \\frac{\\sum \\mathrm{True\\ positive} + \\sum\\mathrm{True\\ negative}}{\\sum \\mathrm{Classes}} $$\n",
    "\n",
    "**Hint:**\n",
    "```python\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.accuracy = pl.metrics.Accuracy()\n",
    "    \n",
    "    def validation_step(...):\n",
    "        ...\n",
    "        self.log(\"val_acc\", self.accuracy(y_hat, y))\n",
    "    \n",
    "```\n",
    "\n",
    "**Reference:** \n",
    "- https://en.wikipedia.org/wiki/Accuracy_and_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Add learning rate scheduler\n",
    "\n",
    "**Hint:**\n",
    "```python\n",
    "    # Adam + LR scheduler\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(...)\n",
    "        scheduler = LambdaLR(optimizer, ...)\n",
    "        return [optimizer], [scheduler]\n",
    "```\n",
    "\n",
    "**Reference:**\n",
    "- https://pytorch-lightning.readthedocs.io/en/stable/optimizers.html?highlight=scheduler#learning-rate-scheduling\n",
    "- https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Add early stopping\n",
    "\n",
    "**Hint:**\n",
    "```python\n",
    "\n",
    "    from pytorch_lightning import Trainer\n",
    "    from pytorch_lightning.callbacks import EarlyStopping\n",
    "    early_stopping = EarlyStopping('val_loss')\n",
    "    trainer = Trainer(callbacks=[early_stopping])\n",
    "```\n",
    "\n",
    "**References:**\n",
    "- https://pytorch-lightning.readthedocs.io/en/stable/generated/pytorch_lightning.callbacks.EarlyStopping.html#pytorch_lightning.callbacks.EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4. Log figures into tensorboard\n",
    "\n",
    "**Hint:**\n",
    "```python\n",
    "    def validation_epoch_end(...):\n",
    "        ...\n",
    "        self.logger.experiment.add_figure(\n",
    "            'val_acc', fig, self.current_epoch)\n",
    "```\n",
    "\n",
    "**References:**\n",
    "- https://pytorch.org/docs/stable/tensorboard.html\n",
    "- https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.tensorboard.html?highlight=tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
