{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10: Training a classifer\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lento234/ml-tutorials/blob/main/01-basics/CIFAR10.ipynb)\n",
    "\n",
    "**References**:\n",
    "- https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Runtime setup: GPU accelerator at Google colab:**\n",
    "\n",
    "1. On the main menu, click **Runtime** and select **Change runtime type**. \n",
    "2. Select **GPU** as the hardware accelerator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![steps](../images/steps.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of content**\n",
    "\n",
    "1. [Setup environment](#setup)\n",
    "2. [Load and pre-process the dataset](#load)\n",
    "3. [Define the CNN model](#define)\n",
    "4. [Define the loss function and optimizer](#loss)\n",
    "5. [Train the model on **training** dataset](#train)\n",
    "6. [Test/Validate the model on **test** dataset](#validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR10 Dataset**\n",
    "\n",
    "The dataset consists of `3x32x32` images of 10 difference classes:\n",
    "\n",
    "    airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck.\n",
    "\n",
    "![cifar10](../images/cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 1. Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages / modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.style.use('seaborn-poster')\n",
    "mpl.rcParams['mathtext.fontset'] = 'cm'\n",
    "mpl.rcParams['figure.figsize'] = 5 * np.array([1.618033988749895, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducability\n",
    "seed = 234\n",
    "np.random.seed(seed)\n",
    "torch.random.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup computing platform: GPU accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "assert(device==\"cuda\"), \"GPU not available, try again !!!!\"\n",
    "print(f\"Computing with {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = 4\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load'></a>\n",
    "## 2. Load and pre-process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocessing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert data to pytorch tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # normalize dataset for each channel\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download train and test dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                 download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, \n",
    "                                 download=True, transform=transform)\n",
    "\n",
    "# Dataset sampler (shuffle, distributed loading)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, \n",
    "                                          shuffle=False, num_workers=num_workers)\n",
    "\n",
    "classes = np.array(['plane', 'car', 'bird', 'cat', 'deer',\n",
    "                    'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "print(f\"Number of examples: train = {len(train_dataset)}, test = {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(images, labels):    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        img = images[i] / 2 + 0.5 # unnormalize\n",
    "        plt.imshow(np.transpose(img.numpy(), (1, 2, 0)), cmap=plt.cm.binary)\n",
    "        plt.title(labels[i], fontsize=14)\n",
    "    \n",
    "# get some random training images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# show images\n",
    "imshow(images, classes[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=define></a>\n",
    "## 3. Define the CNN model\n",
    "\n",
    "![network_architecture](../images/network_architecture.png)\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "- Input: An image of `n_channels=3`.\n",
    "- Two layer stacks of 2D convolutional layers (`Conv2d` with `kernel_size=5`) with rectified linear activation (`ReLU`) followed by a  2D max pooling (`MaxPool2D` with `kernel_size=2` and `stride=2`)\n",
    "- Three layer stacks of Fully-connected layers (`Linear`) with ReLU activaton.\n",
    "- Output: 10-dimensional vector defining the activation of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Define network\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3, 6, kernel_size=5),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 =  nn.Sequential(nn.Conv2d(6, 16, kernel_size=5),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(nn.Flatten(),\n",
    "                                    nn.Linear(16 * 5 * 5, 120),\n",
    "                                    nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(nn.Linear(120, 84),\n",
    "                                    nn.ReLU())\n",
    "        self.layer5 = nn.Linear(84, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net() # construct\n",
    "model = model.to(device) # move model to device (GPU)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=loss></a>\n",
    "## 4. Define the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "print(\"loss:\", criterion)\n",
    "print(\"optimizer:\", optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=train></a>\n",
    "## 5. Train the model on **training** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (x_train, y_train) in tqdm(enumerate(train_loader), \n",
    "                                              desc=f\"[Epoch {epoch}]\",\n",
    "                                              total=len(train_loader)):\n",
    "        # send batch to GPU\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward-pass\n",
    "        y_pred = model(x_train)\n",
    "        \n",
    "        # backward propogation\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # log stats\n",
    "        running_loss += loss.item()\n",
    "    loss_history.append(running_loss / len(train_loader))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(loss_history, '.-')\n",
    "ax.set(xlabel='epoch', ylabel='loss',\n",
    "       title='loss history');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"validate\"></a>\n",
    "## 5. Test/Validate the model on **test** dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Predict using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_loader))\n",
    "\n",
    "# predict\n",
    "prediction = model(images.to(device))\n",
    "prediction = prediction.cpu() # gpu -> cpu\n",
    "predicted_labels = torch.argmax(prediction, 1).detach()\n",
    "\n",
    "# print images\n",
    "fig = imshow(images, [r\"{} {}\".format(classes[pred], \"$âœ“$\" if pred == gt else r\"$\\times$\")\n",
    "                for pred, gt in zip(predicted_labels, labels)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Accuracy of the model on **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, total=len(test_loader)):\n",
    "        prediction = model(images.to(device)).cpu()\n",
    "        predicted_labels = torch.argmax(prediction, 1)\n",
    "        total += predicted_labels.size(0)\n",
    "        correct += (predicted_labels == labels).sum().item()\n",
    "\n",
    "print('\\nAccuracy on {} test images: {}%'.format(\n",
    "    len(test_loader)*batch_size,\n",
    "     100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Accuracy of the model per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = np.zeros(len(classes))\n",
    "class_total = np.zeros(len(classes))\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, total=len(test_loader)):\n",
    "        prediction = model(images.to(device)).cpu()\n",
    "        predicted_labels = torch.argmax(prediction, 1)\n",
    "        c = (predicted_labels == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print(\"\\nAccuracy\\n-------------------------\")\n",
    "sorted_idx = np.argsort(class_correct/class_total)[::-1]\n",
    "for i in sorted_idx:\n",
    "    print('Accuracy of {:5s}: {}%'.format(\n",
    "           classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
