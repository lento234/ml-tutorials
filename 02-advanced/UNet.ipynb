{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation with U-Net\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lento234/ml-tutorials/blob/main/02-advanced/advanced.ipynb)\n",
    "\n",
    "<span style=\"color:red;\"> On the main menu, click Runtime and select **Change runtime type**. \"GPU\" as the hardware accelerator.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 11 16:02:02 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 24%   26C    P8     2W / 260W |     74MiB / 11010MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1918      G   /usr/lib/xorg/Xorg                 56MiB |\n",
      "|    0   N/A  N/A      2197      G   /usr/bin/gnome-shell               16MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## U-Net\n",
    "\n",
    "A U-net architecture, as depicted below, is one of the most popular CNN architecture for image segmentation, initially used for [Biomedical image segmentation](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/).\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" alt=\"unet\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "### Datasets:\n",
    "- http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/\n",
    "- Dataset: https://www.robots.ox.ac.uk/%7Evgg/data/pets/\n",
    "- pix2pix\n",
    "- https://github.com/NVIDIA/semantic-segmentation\n",
    "- CamVidDataset: \n",
    "    - https://github.com/qubvel/segmentation_models.pytorch\n",
    "    - http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid\n",
    "\n",
    "## Table of  content\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Lightning is easy to install. Simply ```pip install pytorch-lightning```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 4\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load'></a>\n",
    "## 1. Load and pre-process data\n",
    "\n",
    "- Define preprocessing algorithm\n",
    "- Load training and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define preprocessing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert data to pytorch tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # normalize dataset for each channel\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 40\n",
    "image = plt.imread(glob.glob('./data/CamVidDataset/train/images/*')[i])\n",
    "label = plt.imread(glob.glob('./data/CamVidDataset/train/labels/*')[i])\n",
    "\n",
    "plt.imshow(label*100, cmap='gist_rainbow', vmin=3, vmax=3.5)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['sky', 'building', 'pole', 'road', 'pavement', \n",
    "               'tree', 'signsymbol', 'fence', 'car', \n",
    "               'pedestrian', 'bicyclist', 'unlabelled']\n",
    "\n",
    "# classes.index('car')\n",
    "[classes.index(cls.lower()) for cls in ['car']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f829a4ddbb0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(15, 5))\n",
    "axes[0].imshow(image)\n",
    "axes[1].imshow(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00392157, 0.00392157, 0.00392157, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00392157, 0.00392157, 0.00392157, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00392157, 0.00392157, 0.00392157, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.01176471, 0.01176471, 0.01176471, ..., 0.01176471, 0.01176471,\n",
       "        0.01176471],\n",
       "       [0.01176471, 0.01176471, 0.01176471, ..., 0.01176471, 0.01176471,\n",
       "        0.01176471],\n",
       "       [0.01176471, 0.01176471, 0.01176471, ..., 0.01176471, 0.01176471,\n",
       "        0.01176471]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f829a510040>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAD8CAYAAAARze3ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABBMklEQVR4nO29eXQk13Wn+d2IyB0JJPa1WFUsVrE2klXcRIlaqF2WrKblRaaO2q1pa4Y+PdTYbrvbprp7xvaZ4bE9tmS3p0fqoVvqpm1ZFNuWWtRCSSQlWaLERVyKZJG1slYUUEBhXxK5Rdz5IxJbYUsAmchE4n3nJJD5MpYXkRG/uO++++4TVcVgMBgMS2OVuwIGg8FQ6RihNBgMhhUwQmkwGAwrYITSYDAYVsAIpcFgMKyAEUqDwWBYgZIJpYh8QEROiMhpEbm/VPsxGAyGUiOliKMUERs4CbwX6AZ+BnxMVV8v+s4MBoOhxJTKorwdOK2qZ1Q1AzwM3F2ifRkMBkNJcUq03U7g4pzP3cCbllo4aEc04tSVqCqVjTo2WCCugusVvmIuh3qrWN5gWAEJBgApdzXWiaKZ7JrWHGd4QFWbF/uuVEK52Nme18YXkXuBewHCdpy3dH68RFWpYERwm2pxQzbOWAprLFnwql7/AF6y8OUNhuWQQBC7oxVkswsl6PgE7uDQqtd7Qv/h/FLflarp3Q1sm/O5C+iZu4CqPqiqt6rqrUE7WqJqVDbq2LghGwAvGlzVuhKLlaJKhi2KlairCpEEkEgECazuflqJUgnlz4DdIrJTRILAPcCjJdrXlkRiEezE1nRXGAzL4thYNcU1JEoilKqaAz4FfBc4Bjyiqq+VYl+bGcm52FO+P8UeT69+/ZoanLZWrFgMcWa9KFY0it3YULR6GqobCQSRcKjc1SgqEituK7VUPkpU9dvAt0u1/apA1e/EAci5q1/fsf2nZ/4i14lJvPEJxHGQaBSZmETTqxdgwxbDErCrbOyJbWGFw3ipVFE2VzKhNBSAZeGF/Z9AI0EknVnX5qQmhh2J+Be+CBIMGqE0rIgVqi5rEvCv/3gc0mkoQqx4lT1GNhmeh6R9S1IyueJs07ZmnPJWTQwsuzjbNVQtEq8pdxVKgsQiiF2c698IZTmxLDTg/wRubbj42w8FsRsSxd+uoWqQUAis6pUBK7rQVymhEHZ9/cyrEGPCNL3LiedhZVy8YAmtPtv2LUwz5YdhEax4TfX5J+cgsShMTCKW74qSeA0SDM47Zqcm5t8fF5fejhHKKkciYaxQqGhObUOFY9ngFdYxKI5T9N7hiiMUxGlt9q3mwBJyV8CDwgjlFsCqT+D1Xi53NQwlxq6tRerr0LEJ0Nnhrd7EJJqb7wMXx8FubamaIPNlCa0/+NwI5VYgGMCKxfAmJ8tdE0MJkWjE7+2ti88rt+Pxha4XqcKQoBJihLKczAkPwiuhD1EEqzbujw03vsqthxHEdWPOYDnxPKyU3ySyR6dKu69gACsSKe0+DGVDHAccY/eUCiOU5UQEdfI/gVPieEcRP15uK/iktiASCpX+GtrCGKEsJyIzwqV26QVsugfcUIVUcSxkJWDObhlR21pzmrW1YtUnNmQ/ho3FMpmkSooRyjIiORc7P4TRSq5vnHfB5HvADQZD4Rih3GqI+KMxjK+yarBiMT8RiqFkGKHcioSCpge8ipBwyDz4SowRyjKitoWXT4qhwQ0M7TA94NWFyRBVcoxQlhHJuVhTfhylNb6xY7FND3h14CdpLkHmKcM8jFCWE8tC873eGtmYXu95uzc94JsezeXwBobQicnVTXdsWBVGKMvJnJE5MrVBvd5zMT3gVYE3OYk7MIg3MlruqlQtRii3MtM94MbHVRVY1Z4yrYyYwaFbnXAIp7MdPA+3fwDNlsGyNRgqnHUJpYicA8YBF8ip6q0i0gB8BdgBnAM+qqrD66umoaTYlj9rXSyCO2KE0mC4mmI0vd+pqodU9db85/uBJ1V1N/Bk/rPBYDBsWkrho7wbeCj//iHgF0qwD4PBYNgw1iuUCnxPRF4QkXvzZa2q2guQ/9+yzn0YDIYVkFAIAoFyV6NqWW9nzp2q2iMiLcDjInK80BXzwnovQNiOr7C0wWBYDqu21mQyLyHrOrOq2pP/3w98Dbgd6BORdoD8//4l1n1QVW9V1VuDtglrMBjWigSC/nhvQ8lYs1CKSExE4tPvgfcBR4FHgU/kF/sE8PX1VrKa0enx1ib7i2EtWDZ2a7OxJkvMeprercDXxL/RHeDvVfU7IvIz4BER+SRwAfiV9VezSrEsdDopRiiATKXLXCHDZsOuiZkpIDaANQulqp4BblqkfBB493oqtaXIW5Jaokw+Gg2Tq/NTqtnJDNaombK2WrCiUaTeZDbfCMzInHKSH+vt1QSxkiWyJvMC7IwkTdKEzYwIyPzmtVUbN6nyNggjlOXEsvCC+exB4QCSLs2oGFEtrFkfCmHX1qKqeOPjJamLYfVIILi4H9KI5IZhhLKcqCLqv5WsW9664OeoJBJGcq4RygrCMn7IsmOEsoyoY8/MwlgxzeJ0Bm90rNy1MEwjgtTWlLsWWx4TU2CYJZ3Bm5jESybLXRODoaIwQmmYxbbxJo1IGgxXY4TSMIttISbw3WBYgBFKwywiWPX1Zd1//31vwd6/p3x1MBgWwXTmGOYhtuWHnahu6H6tcJjsm/fTcDwNgyMbuu+yI4LdUI8El5hgbh1hQGM3t9N/eHF7yJkSdjzcA16FdCRWMEYoDfMJh7AbG3AHBjd0txKLMvZvxmn6HcXtW5hHRRwHxKrKqSqsUMifZ73IaDBAz1sFL5Zb9Ptc0kYDTsnid6sJ0/Q2zCfnliVUyR0covGjPbinzs4rz7z/VrBs5OAecm89uOH12sxcubMFL7r0b6lBJXldGV0tmwgjlIZ5aDaLO1yeKY68ZJLcOw/NKwtfmsDpbCfVFqP7X2Wxm5vLUrfNSOMrY0h66VtcRVHTeVcQRigNFYO9bzeD+0M4XZ0zZd7rp0jtbiUwnqXzPwdJ3r6jfBXcZFhjU8gyA76stEXs2JWNq9AmxghlGRHXQ1xFXN3yDnUJhcglIrS8mMRrrAXA2XENqQ/dgvPDIzivnmGyI0Dkh6+Xuaabh+TuRjS0sZ1y1YrpzCkjM80e0/oB18UZTnL5ribqzjiMvenNADQdmSD7nsNM1NlMdFk0tjSh3VnEtpC6WnR8wg+UN2PTFxA7fgV5Txu6xF2uFmgsjJjUeytihLKciKD2dIbzTWrcWzZ2bQ3uyOi6NiPBIGrbZGqFnrfNTpI1sa0GUdj1+bO4oR2M3tKGHGpjqsFCHWh7vJexQ63UfPtlNJdDc4v38BoWwVbSzVEiRihXZJPenYaNxgqH/USxzvxnqxWLIvH15UW0E3Xkbt7D+Y80kItd1VQUaHzVI3e5DzsDKnDlsMXENYIXELrv7sANCOp69P8vt625DlsRyQrhc0PlrsamwFiUFYAoGx7gvSyWDd78XgCrqREcGx0dn9crbtWubwZNp62VqYNdBMYyRHuUmp4cfbcH8AKz52Nsp036k3cw1SyoA5KD4Di0/XgYmUzhnj5L6kO30fZPg5Q/WZ2hGjEWZQVgpbJIJlvuagB+Tkp7A6cXGH/TdsJHzsFzrzK6B6LnRuh6MunPGJ8nU6uM7wAvCNu/McKOR0ewU0rH/3cRycd8hr/3Mu6xUxtWb8PWwliUhnnoVAp3cAhxHNRTrGBg5ZUswYpEUNdF08tnUpdQCNm9E2t8ElyPyNefm7ECd//NEF446EcCqN/MnovnKBffnyA0otSfyPD8l2+kIz6EFYtx/C/3s+8vRnFfP7m2Ay8jVn2i3FUwrIARympHFcmtPvTIqokhsRgECrhERLCaG9FUGjzFHRhY1JUggSDjdx9m4EbBmWwgMAHtfz2Il0ph19bS/f5G0g3LuCAEsnElG4fJjhAdP04jF/sgGGTfvz2JN5Va9XGWGyseh0IeRoayYoSy2snmsKbW2NFSiEjm0YlJ3MEhxu+5g7pHl0j+e+h6Bm7w65KLKbkYpN9+kMgrFxl/03bS9YX7adVWet4ehLfto+4NZbJdaHkhTeCJFwreRimQUGhFq3oGy8ZqSJi5bzYBK/ooReSLItIvIkfnlDWIyOMicir/v37Od58WkdMickJE3l+qilcFqxCiNRMM4MZDBS8u4RASWn55CYVwOjtwOjsWzOUSf/iZJTOkq7AgZvTybUHO/ctd9N1mryqe1MoKO742RqQfas9M8R9+/cvU/O+XCt9AkbGiUZzODuyWZn+Y5UriJ4Ld3GhEcpNQSGfOfwM+cFXZ/cCTqrobeDL/GRHZD9wDHMiv8zkRMbMiLYFbU7iAbRgiSCE3b8DxX1ctO/Trb8aKxQrenRvRhSFBBeAFlIldNcS7c0y1hvjMn97DmW9fy8RH71jVduxEnd/Lvw6saBSrrtY/H7aFxCLYjQ3+lyL+9qdf0+uEQki4tL//2E2teOFl3C6CafYXyIpCqao/Aq4OtrobeCj//iHgF+aUP6yqaVU9C5wGbi9OVQ2VRq6ljrGb2xm/qQ0sm77/7S0k3kjhTW5MAPNki00uYhHpS9Pwxae55quXCYz7XUNWOFzQNk7dvx/7+mvXVQ9vagquii+dtsqdzg6cbbMvu7HB/y4Q8DM1lRA75SHe0g89DSjJ7RsX4bCZWWvbr1VVewFUtVdEWvLlncAzc5brzpctQETuBe4FCNvri8UzFBerPoFOTS35vd60hwvviOMGfYsQBSu3g1ifR++bIwT3vZnwsBL/yjNLbqMYJDuUTJ1FzUX/s3vqDNErg0hnB1gWVi6HOzC0MIelZXPlN26n/dHz1J0ChmZHFdmtLYvmw1wOu6524Zzbjo1dX+9blHOsbonXYEejYEnJm92xY310Bdu4cjhA7RklNOaSC1sM77HAguYjOWLH+kpah2qh2E6yxX75RdtVqvog8CBAXaitgqKtq4xMFntslafXttFU2o9RvEoAMod20vPWMO7cZAsCQ3sDdH2jj2hPnKnWEOO/Nkb9P7WS6+svaTC9lYNMbYBILOZbsrY96/u1g1iJOtwr8zPkSMCh8dUpBt693S9w3Xx5EOIxZCi4ugTB9iJNdxGkbgkD4GpRLSHxly8Tf3l+WX1pn19VyVp/sT4RaQfI/59+BHcD2+Ys1wX0rL16hnUTDKzeF+rYWK3NC25ojYa59ParRDJPul7p/nArU60hBm+w4Z/qSf1dCDuRWEflC0BAbUH37lj8a+cq32A4zODHb+bi+yKMXgeT22af7dm33wCWxeA/v2XdfktDdbFWoXwU+ET+/SeAr88pv0dEQiKyE9gNPLe+Km4dvERNaZJjrCU56yLNwqGbG/Ccpa3D2vMuTtJDBVKNSvfTnVz6xD4u/9ZbSP/cbVy+s/guFjsF3e+ykJMXEMdBotH5C4SCyJzoAqmrZWxnPnOO5Qexj75rNwCeI0zsa6TuXBp900Hspsai19ewOVmx6S0iXwbuAppEpBv4A+BPgEdE5JPABeBXAFT1NRF5BHgdyAH3qaoZflsAA2/rZGQvhIYSWPnRjJEBj4ZnLldErspcSx3j26z8wPTFSdVZBB2ZXUYg1eS/7212WMILsy7cEHhhj5EPHwCFWG+G0LmBectY8Ro81/WFdJGe5tGdFvqrd5BssZhqVWou2HhBoTXbTurNu4h+/7WZ5rmX2nxB7Yb1s6JQqurHlvjq3Uss/wDwwHoqtRUZ2ylkmrJkmmbLRlWIDDQRObm6zoWiI0LPO+IrhvFEB1wCEy7ihVBrY9zOmTolOGQztN//PLI7THNdGzWnRpBkXtQStQx+eA+TXZKP5Zxft2xcGbxBmBbyiWsAlEvvrKX+VI7zv30TWH4yju1f7cc9cXpDjs1QOZikGJVMhcxpMrmvhWwBkwQmW2ySrYENE8nF8IJK3202Fz/UxNjhdhAh25lgbBe4IcULFl63XAQGDji4EcUN+fGeg29q9tPNBZaYWtZQlZghjIZl0VCQ4T0B1C5QYCokfiFTp1w5bJFKdJBsn7UWV8NiojqyB+pu2k2gZwidTPpj6QuM2TRsXoxQrsDUnhayMZv40StIdutlz9aAs3yiijmk68VPoltGi3IuasHYLii2evfeGaPriSyWGX64ZTBN7xW4fHuQ7vcrGq3A4YYbwPBNiQXpzpbCSoOd1oqxKktFJqFMdRY+TNOw+TFCuQTq2PS/q5NMwu9xHt23NYd6ZeJScLKKwIQSnNTlOsYNhk2JaXovgoaCdP98C+O7c0xnkI2f2XoTMGksQi5auH8v3Si4ocppem8FNBJicle9P+NiiceOb2WMRbkIXjzMxHZ3XhiJuB7qbK3RGpmWWMH+SYD4eY/aCznENb67jeLS+5q58PPQ9+423HqTM6FUGKFcBHtgjO3fcpHM7OlJN0fJNdeWsVYbz9j21flls1EhG1s+KN1QXNINgChDN+c486u1Jr9liTBCuQTRE/3s+koaZ3hreifcxjgTXau76SwXrFzxRNKNKJkmd+aViym6NX+OgsgmXIZvby93NaoSc9ktw2RnmFx9bnaWK0sYvqOD0Z3+86XhhEvti72lq4ArWNny+J0mr6lZVXA2QLJNcCbsovgovSC4MW+edepFXRAbZ8JYTYthT1rUnh4vdzWqEiOUS5Dc28rlt/k3aaJ9DDdUi1oBeu/yQPLjfgMB4sfDs0PlikzsgkP4jcsl2fZKhAcySC6CrkIswwNKYFKZahN0vW0V03pfNZIV7EEjlKXANL0XwauN0vM2Bw34oUEjQzGs7MI7N1ejqFO6U5iL+D3P5WCyI7RqizJTJ2RqpeC4y+WwchixNFQMRigXwRpLsv3bU9jj+V7utI0sksCn7qS/bMkQRTeRc94LgBsoPO5ysyIeSBF9scXCjXpMXddc7mpUJabpvQSBnmFiFzsZ27+0jzDZJmgkhEwVOD3pKvGCoCEbJkqy+YrGc6hYwQ2OCNGTV1ZecKNRwcopuZY6Rvb6WUzCQy41R8vjvqkmjFAugdoWEzt9M7JjxwBuuAkU7NoM7rg/c524gFdCy8IDcSvPclkKJwmBZH4I4zpFzspSlO2UguColnR6i9UQGoZ0m/9ewy5j20OMXB8i2+jnJZCcxc5kM+EzFSjsmwjT9F6C8Rtb8IK+UAYsDxUhF7E4tK17ZpmpLhevhFPOikdFJO0tFCurxQsPqkCBBBBXaHq5cjpMAhNXnW8BNzpbpo6HFzS3+Xqp/DMoglcT3dhAWvGz4EyT9Sz6b7EIjru8cHznTHn4so2VXMUkVKskMCHr94Fmc1gTpavjXMTNv4qglZXa9K49o9gDY+Wuxgz1x5eeLdNQPCpeKN2GGnKJMF7dxmVrcRtqiF1KUf+K35nTc74RZ1L8pvCc0TrBUaDSU6/Zlu/n3AiEoonbTNO7ggiOCI1HRspdjXkM7Z8fFTG6i5mWkKF4VJxQqmOjkdDsuOr8ZFtqb5x5IWkXREg1TgeaQ8d7LpJO2Lz15mMzy1kZ9ad0rWQsCw1sjFBG+10i/VnEq0BTsAg0vpbFGq2s5CiNr85vccTPg5WpuNt601NxZ3T8hhaO39fAyK2t5atE/qzY2fnFoTGXHx+9fuZzsl3QqMluPc3wboeR64LLztS4LlSQbHlE2J4SgiMb48JYD5MdQuhKxd3Wm56KOqMacOi7zUIDHlcO+6E35UDSObCYzZyjcPbFLiSnWOOz1lnB0yOsETfop3zbNFiUdo4f0ZKf86UITECgd7gs+14NdWc8mo5WuDtoE7KiUIrIF0WkX0SOzin7QxG5JCJH8q8Pzvnu0yJyWkROiMj7V1MZcT2il/0bLdIvZfP/ebW+38eZzN/0nlB/DAITObZ/J4c9YWNP2FzzeAqZXL8zPdkVm0kQPJdUR47U9sS6t181qGCVyaKsVIb3zZ/HfGyHhRs056jYFBJH+d+A/wT8zVXlf6Gqfz63QET2A/cAB4AO4AkR2VPw3N6eR80ll9EDEOv1ypqIVEVINc/u3wsAqoTPDbPnQf9ClHSRmmJLdIJEzztETvcUZx8bQHCkeGO9dbFeb/FnUTRiOUvijRQDb5q9jWu6FTtTYb1gVcCKl7Oq/ggYKnB7dwMPq2paVc8Cp4Hb11G/imHujS/pTPFEEohenCTWvfCnCI6zqeIoI0Me4SGXogz2Vj9mEVeQdP7ceFK2nvBAsjLFRzLzrw8rp9gpD8lZWEmb+IkAkfMj5alcFbGekTmfEpF/ATwP/K6qDgOdwDNzlunOly1ARO4F7gUI27OZmad7t9edfaYIiCcz96WU2LjtemyA4d6G2QKF+hf6SrvTIjN6re2nWSuCH1FccMYsYpeEmh6X0Z0BUk1a8t9hKRpfrsxxpItFg0RP9LPtsTaCoxmCFwfLUKvqY61y9HlgF3AI6AU+ky9fzJRY9K5R1QdV9VZVvTVo+34WdWxGr/WrNLbDQoOBNVZv/UjOo/7V2cOxM/hB70UMfLcy/l2vARsyWRp+2jP7eroHyWRX2EJlERxVQmNe0aw+cSFTC+HBDJ5T+ofVcozvrMxZFy+9I7poec3Ry0Yki8iahFJV+1TVVVUP+Gtmm9fdwLY5i3YBBTvZJOeSOOXfDXVnvPIJRb65Ozc8yJlS8LSoTW6Z9PNYStatiomhvID4mXWK2ErVfJBBTXd5XRCV0MJZDMt0cG8Ia/r5RWRuvvmPANM94o8C94hISER2AruB51a1baWsvigAa8zvyY725wj3Bmj5iU20r/Jj6MpNLgqx3kxJAs7L7SO0KvQ5tu1bQ7Q85RA/GcCatImfL00mq63Oij5KEfkycBfQJCLdwB8Ad4nIIXw5Owf8BoCqviYijwCvAzngvoJ7vPPEX73C3tNBJFXGZmc+M0zoSpKdX8kgU2myHfXF303UjxP1gg6WY1eFVVmt5EKV2dNuTSRpemqKTGc9GrBMc7tErCiUqvqxRYq/sMzyDwAPrLVCks0hZR4/rTWz42dLlWuyWsmFbTxHUYtFkx1vVuqPVU7GoMWwch6q/gCFYrqHDD4mH+Vi5Pw73EqVWLDzlqtUSG7D9ZJOKJfe4cxMyOaM2EXxoQ3uC+OUO0lOJWeaV0Wyrj8qqkqupUqjQl3UZWY6RCl/c2jAf57YxU6pNm1xeYqUMgHwBqA2ZOtdXySnKcLVlY0rb/nkixy+7wiZzvJZSv231pRt34Uwk+DZCGVJMBblIshkCqkJYV09u2KRL0LJ964Xs5e4XHhBhfw0tZK1sCctP1XaOlFLaQuNEhAXKdM4b6CyhwWK4EYCvkUZDFR+6r9NiLEol0AFNOwnpJj2mUqx59ievqA9b1ONwFmUaQ1TwU4WRyQNVzHd/L/6vypWJue3SoxIlgRjUS5Gvqk9bUF6NVHUEtx4GGcDOnfUscl2JrCTOewro3h1Md/KreBecTsteAGbuhMWCCTbi2P9NR+4QkBcRnMRNLVBCYg3kGxHPckOP1Xf4AEbK+snLXbDsxnjPQciV5Txa6HxZeXKzULLC8rQL04S+WGcWJ9LZCADrqLBAF5dFMm6WCOVOZpoM7KlhVIDDrmWWgBO/4bFrk5/AqaBrzXTdCSJFw5iT6WRTBbRMFaJQpa8oIMVcJBsjvSOJgb3h0l2KE5SCA/UkKkTnEk/ljDanyPcPzV/CopsblbcM9nyCKpCYFwITihj1xanmaoW1If9XpyTEy0E+1e4XCU/hUS+PtMuDfH8z5of3aNWeUf5THPxl7rI3jHOgbY3AGgrZKU782OC7/CzzvCxXpK5ION/tY3wlTQ4Fuf+LWSSEfb90aTxWRaJrSmUIowdbqP3l9O88PbPA1AjIWzxPRE3jn8MjoSw0tmZ5cX1kGSRrEnLItORwAvZWGkXtYXJ65twQ8LgAdv39wG5qDJxDYCSqfNXHd3lIBqfl3gi1qN+EmGB2CUlF52dW9ufaxsCycI7I+wpJTyythusGPkwALLb0tx87QVurru4qnVu3H4JgPFsiJGpMFnXJp0OkE07NDZMMDIWJRpNM3UsUVaxzHbU50Wyd93bijoZ3rhnCvuVGpqOBnnzNcdwxOP4oYPUvrT+7Ru2mFBmuhq49M4ov/fxf2BvsJc7wjYQWbDc5Nk6IEWuLoI2RLEy+dALywKWvru8RA3WWJJse2KeYGTjAQZvmB23ruLP2W2noO1pP5X/0F6HTEJZcUiSTIvR7HIT22Y/Dx9QDh46S3AdcTkpN0DveJxMfy32iIM9JagD2YRL544BrGV6n6YOBdBkCH2jZk1CVH/zFf5y71focqbwgC+PHgZ8MXBDYC/2rBJfJA9u78HJD6GpDyWpDy2cmG173RCeChdvcBk+0YA9VZiyB8eLa5n13RbjQNvJom3vho4e6IDjuT3sAq6L9vPEe5V9rwU2Xc6ASqQyhNK2FkweJlOZov7A2fZ6Dv3Vyzze9tL0Tpdc9o8/9GX++n/8IlduipJsV+LnoP5EirEbmhjeY7PtidngYy9oM7TXF9tUkxAarvOFa8H9t/BGm5tX0StC/o9cjbJ9f++6RBIgbGfZmRjiUHMPO6MDPD+8nYtjdexMFJhtrw6O0o6enG/FZhpcv/vQUkKJFLbtkRyMYo/bWFnBDSl/c+Ah9gRiQA0XcrM+tgM1vYzcHuW1F3dgT/ljytUC3TFFOJJhX8PgjEiuhCXKoeZLPDkQx+4uLIO8nS6iUFoW9rtLM4LGevMw7aFRAOxEBhw/4YphfVSEUOo2F++z80c+nDraRcePlZrz65yuNU/f72f4sxmRXJ7Pnn4vcWYTMrR8/Dyjn9vGrt85xn/e9gQT/6t/4bmq3Pn13yUwOnMkZOOLbXFlOt5zkQtPd61t5Txte/tpDBdv8qvRbJj3xV9lT7iXR6zbVrXutsYRzsRiM1nis/Ue+/Z1E8yLmSUelihes/DJjh/z/OS1/HbjC9RZS2fpeVfTcR765a/yry78PJcnawnYLvFAalkLdymGMxF2b+vjFK0zbjwZdwiMLR4IMq3BqV3NDO4PYeWUtif6GD/YTPzVfi6/pw0vIDQcSxM5fWXV9SkWt7VdpCZvdv/SviMcqb0R5+owN8OqqQihtEWJB+f/mDfffJqBfTVceqIDNwRuWGn/iZ9SKnpqsOBhjtnOBi69I8rXDv8ZUFiqrDtaz/EaN5DLt8ovfmsHrQMpapwMUStIFN8KOZmdnGcoRm8YJvnq2saEh+x1WIECuWtSNEaK81CZyxeuvJ2Mt/rLpC44hdWaIjsQQkMe1+/uIeosDBi3RPnJ+B7+Q/PzRK2FbpC52Ci1VpiHd36fC7kJHrj8XgbTa09/Fg+muHnX+ZnPE9kQLZFxnn3ywIJlp5osBv80QW1snOvqzpPzbI6/s4WWun7OjNawt/UMjuXyxlAT/D/Ny4plz8910Fl7ds31Xo7RbJikFyRupwhb2ZlBE4b1URFCuRRNkQmaPjzHj/N2yHk2rxzZyTXfcYkdWyGxrQin7wlx5pc+R6EiCfCW+CmOyo24+bnNIgOKZBfGOf5x7wcIjM9aIGsVSYDXX7mGNbW+BeoODXBNbWkmvlqPEN20rXt+0r0lODnRwsmEcuiqueQsfMvTy+c4S6nDyWyKfcEoXxm7icF0jO7xBONTIbbVj8ysF3Uya7IyawJpRjIL8zuqBfEP97IrOtvqcSyXg+1+R0nLnPJdDQOc/JSQ+1kXO7/UvWBbXqKGiTuThK+e4rOInJlsYndNf8m2vxXZdAHnjuVy882nmbxvlOTe5ae0vfThTn5092eWXWYx/urMuxFVgqPLL/f/dj1JdpFJwdZC7MLaYgSztR476gqdqaNyeSW9MBH+qGczsIgv42R2kp+N7ABg5GctOE/V0fOt7Vz4wXa6v7udZG7tM1d6KmTrZ39TdaDtlss0RQqPSdzTeIXaO/tJ7Wpe8J0bCXCgs7Q90RnP5komznA2ysj1iyf2NayOirYol2N73RDnPwW9L3ay64uXZso14DB2UzMtv3mGL13zGbqc1Y/RVfxpV8cOZgn2LX2KQuKgZRx/6AWgcecwXrFicsrItwdvpM35Me+Lzlpaj0/u40eXd/ELXa8A0OyMsycQ5mQ2NXPM00HZmTpIteQI9zvoOs5Ha3icf/Heh4lZvp8vqw6PDd+wasu6Kz7CqRtb6Hpjfvm5fxbl4AakVepP+df9lXdkqD3fROjsQMn3Wc1sWqEEXyzPHBJO3dtJ/XHof1uOpvZRfnr4cwRk8dCfQpgRnhJroApowEKyHtE+JZMofF0vAPUHS9fk3mhynsXjYwd5a/hZotZCi7DOTnJ37By2LN40TrXl/FkanfX9aJYot4UusTPgC82El+Lh/rVdRxM3T9Gb6qT9u73+EFXLItuUW5NbYK3cct15zvzrRtr+jQkTWg+brul9NdfWD3Lj207R+C/P86fveITHbvqveZFcO/961xN4tnDnwVNFquXiJLfnOPMLviikmlZnBQWvG6sakZzmfLKBpC5+Mx+faufHqabFV1SwksW5lIczEfrcWWE8kbXWbLEf3nGRjl89x/iNLf62b2vjwO6FfstSUx+dYvTQQjeAoXA2vVBOE3UyPNJ3G382cCeurq9pc/8zv4Sd9XjpG/tXtZ4XgEyTu/gUa4thKxr06+qtQtvVhnCw+qyDmJPBvurkjSXDuGpxfLSVJ0YX9kaDP1Qx1m0RGHYIjK/fDfG10VtmrqHvT+5bl2vjtTOdxE6PATDVaJW0E2cpxlJh4m9UduLhSqdqhHKai8l6vjDWxbeS4TVv40/u+EdUBC+0/HIPTzRjz7FktCvFqz//V9jXl/aitK+bKDz4exPREhrHujqc5fk6srryU8TKQbRHipK1qD8924HkrXNWsVhiilx9BHVsnA+Wx0+4vW6Ik78Vwqs1HTtrZVP7KBcj49l8b2A/liiNHd/LD1NcHV/sfisIpLoyBC8vHbSTsCfnzc63q+0K416O9IWagk6sNWETvmIBGYJjhfso2xJjhS1YgYxnwpy6OCdaQZS911z2xytPNPFZ61YuTDVgobwtcZLknjR2vvNjMhfikYk6bggWP150MY5lkrw0VkB80zLsbe7jcssuAmUecn3j9ktcvnEnjU9tzLmrNqpOKKfxVPja6C3cFnpxJtlFoZz96TVck0tR/3yAyWUGy/xt31twknOSUwTSNNkRth28TO9z7UuvOM2cod0FGE0VxWAqRn0oyXA6iqogojSGJ2fKF+uwmMiGuPDja2h/fU74jcDpm7YTuH4M69k6jsse6s56qMBTN9zA9tt7CeQHjT/z9Rt5YeJG3v0/PbNkvURhIhtcMIBhNYxmwuz72/vI1rrccsOZNW+nknAsl763ejQ+Ve6abE6qVijB7xx4IeNye2h1Qvl/fvTv+dxPPsreXzvOCz/YW/B6v9f1HQJic32ij15WFsrgiEXTUX9EjrPJHvQ9z3TQHYRYd37ctQ0Xtyle2CN+43mCMjvS6PJkLZdfbSU0JNSfme8/FoWmlxVejiNzfMuikDgB51uacdv836/mkuKklMe/dAd7PrJEQgmFKyM1tMdWZ3V7KhztacdxPKYGorQfUSY6HbyDsqG91IbKpJDparcBf4OfLs8DHlTV/ygiDcBXgB34U9Z+VFWH8+t8Gvgkfqqd31TV75ak9iuQ8yy+N34DNwVfJSSFj3u5LXSJ9G8O0RkZ4YVCVxJ/FMlyyTauxgsombhFcBjSCWG5eCTx/CQa2bjOjJcuJ1ZWaHo1n+gxT+wyXLnZwsqXnRpsZmI8TM0LEVp75i87l+V0yIr6gnt+sAF2CPUnFWdKeencNsRWQov4JB1n9Z15r3Z30vAdv7e7PuVXKDiinBps5vomM8plq1OIqZUDfldV9wF3APeJyH7gfuBJVd0NPJn/TP67e4ADwAeAz4msM15nHRwZ7eLzI7tJLxF2shhfGr2V6J8n+NnA9sJ3NOdm/2jjc+y683w+UawQPDBK6OAIoYMj5GqUu953hLvedwQ3DKFhX/Rilz2cpBAcE4IjS7xGITgiZFbTRb7BNBxV+pI1ZDyHzEv1tH0jRE1P4cLl2bOvXBQkPw+PZXnsfOc5et/hERpR2r4RovmbYYJXGY7iQuR7cY5/aw8vnNiBp8Jw2u/ESOaCpNzAzPtLE3WMZnxxDL4axUn5Fus0yTapLpEMemho7aOWtjKFzOvdC/Tm34+LyDH8JMt3A3flF3sI+CHw+/nyh1U1DZwVkdPA7cDTxa58oTw1dB1Ztfmd+lPYYs0LH/rjwf18r3cfn9r5ff7T2Xfx5pazfPPMATrSLukHW+EQjG8X6k7DYy/cyF3Dbfzd3r/DBoZTUT+Gb+8Eu1uu8PunfxnXs7h4volQbwANK+FB0B8mZvYXV3jmnJ9jscaDXNQiMA7ZmBAoYJRcLlIZFuVS2BmYfKyVE61K4/HVWXZuENIJazaXp0Bz/Ti2eGyrH+HS/9hBLZBqAGdK8QKL+HbFt1DrznjEzzu8OnQd0UvCuR0eoSGL3IEJbuzs4cSlVhofD3PxQxPUtS+cC1cFwm/yU6Ed628lORTllr1n8VTm9YRPZ0HaDNy06yJ9N++k4emecldl07EqH6WI7AAOA88CrXkRRVV7RaQlv1gnMNfb3p0vu3pb9wL3AkRaSz8V6LPDO3k4MMKz49fyvW/NpgwLTPoJdP8o9nECk/DtUDuxKwpMYWWV8KDgTCqI0P4Di8ln23lf1++hlp9ENpyC7JE4J4NxQiO+RVM3e5T+36vuo7WMYPOb3oraYFuVPRFZ7LJH7PLq17Nyft7HuZEErjf7QeZ0fGVrVo5ttFxoed7vMavpBfDoaQ/jdQg6GPKTXUQXz1ovCtkfNfLyzRGsMxFqBwX2wkunttP4zKwbJxMXpm5NUhNLsathgJxn83pvK+pZNNWP01kzitqCxsIsl/R5I3j5jW3se9EMZVwLBQuliNQA/wj8tqqOydLpmxb7YsEjV1UfBB4EqN/bsiGP5B+N7uEH3z9EdJGcqYF8Gkc77YuSF7RRWxAXnCnAgtilFIgw1RLBC8x2wATnhE26IZjYm6Hu5bU3ccSDwLgvirmIYKf9JqGdganmqgt9nUE8CI3OvxT6R2OcTrZw8tVt1Ba4HZXZAH7x5j+oWn9qceLiblrPe1g5ZepbjRyrbyLat/ASrL3gUXshDCjZCBx7bA+JMQiNzj6oQqNKvDvM8J4o/W9L0326hdanBMuF3reH6LxplJFdFunaBGFnhWxXpSZjIenyzY2+mSlIKEUkgC+SX1LVr+aL+0SkPW9NtgPTzpxu5ifX6gIqwtYfTMdoO3yZvp1xMsNh6l5f/PDTdUK6bjbaXG1QETKNAdyQhdwxQth2cZ9sXGAt2mmofaUwkZQcOEn/pguOe2Rr/LtbLX8WvtCoEpjMz5Wd308m4S2a17FaaX40zFG5gbp6Cy3wse6GhKmQ/7wOTKr/4En6J9DOQOKNWaGLDCqRwZWf04EpJXF66eUSpzyyb7TSNkeYI5dsTnS24KT8ecGdMrcEos2TZLoaCHZX32CFUrOieSK+6fgF4JiqfnbOV48Cn8i//wTw9Tnl94hISER2AruB54pX5fXREh3nfz7wE0L9y3SIyJwXfvNq+PoQ49scJtss7B8k8J5YKJIzqxdqH1vg5W/oXGT+T+GGhHSt4AXmb6/hVaF3slDbqjScH21Y1AIrBeL5TejguBY+B8+c3y9bI2Sjpc+uJOrXc+5vVXfGI/L1OmI9HuERj5xX3taA61qIgsbWluRjK1PIM/pO4NeAV0XkSL7s3wF/AjwiIp8ELgC/AqCqr4nII8Dr+D3m96lqRfU+PDu8k8ANo2SeTwBgZ/Pzr1hgZXxfmbj4HQNevikXENY5mm0BaoFn+zfxYknE3bDghvymt5WF4KQy2SlsC5Z+bvHlcD1ho/uTnLQiI4raQjYGai8vfipzpqst05StorOWbCXMGhuPphm4sRE7HSF2OUf0jUWSqnje7OwBIv7Lq2yf+EZQSK/3Uyyd5uHdS6zzAPDAOupVUhzL4/793+Udt5znfC7Kf+x5L9siw1wfvcx/Pfdm+voSyFCAupP+PNUqgnhKLjz/NHgB8IIltlbEF0xEYRLSDR41gY0VSk/nB11PToVoGtv4O9/OAlnNz8S4cP9q+W4SKwvZqGBndd783pXEpYk6Ll9s4PDecxvSa+6pMHAhQV3Ab6WM7AowurNlwXJ2Sqm9mJ8TKmSRCwuh0dmnYmAsg3N5BERwm2qxr4zOf1+lVPXInKXIeRZf6z/Mts5BXk1tw1PhfLKB88kGOmtG6awZxbtWeCmxnZYfBmZi6+zs/AtaLT+kRS3IhcHJj5rLhf3OITe49OyKwXF//u1UvUUmHsFzwMosE3Cef8jXvyb0Hqxd9ciTtTIwVcPINzqIfejyzD4zoytkCykxS7o8XGY6loOTlaWO4sGVF1ppe/sYOc8m+d1W2vo8zh7ZTfIdE/50syWvw5yHuiw+bDYXE4b2zvexT7bPLmhlA9j5JMZuEOyMH7HihiA4HiNxfPEYNyuZQTbxJGdbUiin+S99b6dmiY4RS5Rbdp/jBXbQ/l1n0ZtTPGZENDBnCOL0e2cFw8+e08MbKHAIYyCpJNPBBVMApdwAjnhkPJuwnSXlBmY6fXKezWQuSMjOkXXtmfAiTwVXLeKBFMlcEMfyFqQBy3kWkQGP8VSIxohDzrNoeMGh5FmNqwxRiJ+F17J7AKgb8LBciA545F6ogY7ZZSeyIU6cbee6HWvvJbdYOGGf5AQro+tqBXl5i3Tm8xxNTTUIl9+yuP88MK6Exv3rLjyQJdgzmq+Tuyma9ltaKJO54IrzqzS3jgKNG1OhAhCFzDMNcFXKrteOb8NKWkT6LSavyVFz1mFil2+G2pMWDa8I49uFaJ+STvjpyOwMBMeUN27zqD1pk6mD7P6kPynYVfuM/vc6TuxPYKeExEjlX9iVSGhMCb2+8gPm1KUWWr/vMC4L5xEqlFxE6P3QCHsaZ2eDlKwQHlEyy4Qtu0HBzrds/OiL4riWsnEhG/ct08k2G/b7aRDDIx7Ry4WNmgsOJrFGJ9GAg8bCWCOFz2O0Xra0UBZCS2yC0weaaDxaORbU1R0po5kIDS/ahEcU8Kg7YwEetefn9j4pDcf9YwgPzz+W9h8L4BHrg/GpKOOt4QXWiJ3NJ68wlmTRifV4vPD6TmLNSSZHIrT8MLDAzbNa7IwydL4O8kLpqUXiRD5WdRn/smfrzPWlAt4yLoxcWGZaVNkayXeIyoqZsNRiJt5mqsliqqkwV46dCmJnEn4nqAN2pg47o9SdGPezUEwvNzoJqmg4CCIzTX6NhpGpNBoO+v9jEVAtyCVghHIFwnaWXLTCxMHzm9NO/oo+fbKd9iJ1rsQvepzpa5qxKjOubS6SEmNnoONJG4jnR3UV57cUl5kW0/ELbbSkVt7u3IewaL4DbQnmirmdf/i6AcULLLRC3eD8jk+dE35XKG5YcMNzPwMIU02zY+FQiF32TeZszEIt32oFSCUsQmMe6bhFeNRjqt4Pl5r+nmWmWjf3wCYk3u1x9Llrie0eYexKDbXHHaSIfh65EOFktJmJkSjxIyECFe5D8hwY3WVRf6Ky67nRtDwPly7uAIXWfg8rt+Iq68bOLuz0hPzotjmOfj/pifiRJMUMHJH5nU/AzECOue+n3QBXf78URigLwI16eLa14bGDSyEeNL+oZE8k6Bjzm9vFpPlFJX0qQWtSsdxNID4KwZHVrZKJybw4x2rEykHNpcr4/eQqr43tgTWmOMuc/+mY2ZnPkm/Wl2F2ZiOUBXD44FleCuwg8XKA8KBXEYJpucv7mtZLaLy42/YcGP/lcdKpAM1fDxc1ttFyIda3OkHI1Mq8oY2ew4ZYXIZZVmrak9WZkDsAFSUX8X2h2dgyalkCITVCWQCWKLfsPcv4tWFOnmuj9fvO8j+wYQHiQvhbtUS0fCNl5lLTO19Y++5Q2n4qa8rsZNgYplsAKku3BHIhwQv6PlA3VLxmvRHKVRAPpji8+zwvpXfS8cPqzeJTCkSLb6UWk/anytCeKwJTDUJkqHLPaym4uhk/l8CUwtT0sOPZhdygLBhZtxqMUK4SS5TWHUMkm1qIDhjzw1BeJnZAxCQDWoCoH00wjZ1RghNrf6AYs2gNdMVHyNStvJyhOhm5rnJum+YXt5Y1WS4q5xc3GDYJlvFPbzmMUBoMq6T2vHG5bDWMUBo2nPFtFm7hswdvaqYahXTd5uwoMsxihHKNuGFmZws0GAxVjRHKNdL4pstlGSFQDcQvelsmDjUyqAsmTDNsPoxQrpGg7ZJKGKU0GLYCRijXiGN5uBEjlAbDVsAI5RqJB1JMXGN6Pw2GrYARyjViiRZ9VkaDwVCZFDKv9zYR+YGIHBOR10Tkt/Llfygil0TkSP71wTnrfFpETovICRF5fykPoKw4RiwNhq1AIWO9c8DvquqLIhIHXhCRx/Pf/YWq/vnchUVkP3APcAB/yqQnRGRPpc3tXQwOHjzPpZd35qdgMBgM1cqK9pCq9qrqi/n348AxYLlZj+4GHlbVtKqeBU4DtxejspWGI64JETIYtgCrajiKyA7gMPBsvuhTIvKKiHxRROrzZZ3AxTmrdbO8sBoMBkNFU7BQikgN8I/Ab6vqGPB5YBdwCOgFPjO96CKrL2ibisi9IvK8iDyfHplabb0NBoNhwyhIKEUkgC+SX1LVrwKoap+quqrqAX/NbPO6G9g2Z/UuoOfqbarqg6p6q6reGkpE1nMMBoPBUFIK6fUW4AvAMVX97Jzy9jmLfQQ4mn//KHCPiIREZCewG3iueFWuLEb3mI4cg6HaKaTX+07g14BXReRIvuzfAR8TkUP4zepzwG8AqOprIvII8Dp+j/l91djjDX4spdUxBRiL2GCoZlYUSlV9isX9jt9eZp0HgAfWUS+DwWCoGEy4tMFgMKyAEUqDwWBYASOUBoPBsAJGKA0Gg2EFjFAaDAbDChihNBgMhhUwQmkwGAwrYITSYDAYVsAIpcFgMKyAEUqDoUiomLneqxUjlAZDkRj4SJLBG41SViOFJMUwGAwF0PzVKIukXjVUAcaiNBgMW56VXCZGKA0Gw5an953est8boTQYDFueju8vL4VGKOeQ82xeOL6T/mS83FWpOgYPWPR+KEOyafFLLhsVhneby9FQmZgrExhMxXj9O3s4/9930f6kTf9oTUHreSpkx4Mlrl11EBqCXz/8U/Z9/BhXbl7oELKySnjQdIQYKpMt3+vtqXDuTAsdp2Z9FG7OLmi9I+e20fJjB9PTuTI1vR6P/V93AdC8yPmysxAZMufRUJlsaaEcTkc5c7qN5qdt5opd7OkoXpdgydI37sBUDS3fC2JnzM1tMFQ7W7bpPZyOcvnJLjq+bxGYmi92kUGPI69cS85baFl6KpwZbqT/mXas7EbV1mAwlJMtZ1F6KoxmIvQ93kXi7OIhAVYO2p4Sjg9di7dnEs7FaDt8mZpgmhPdrTR/N0Qks3w4gcFgqB5WFEoRCQM/AkL55f9BVf9ARBqArwA78Ker/aiqDufX+TTwScAFflNVv1uS2q+B00NNRL6aoDa9vNCJB41HFfdEFCunpF9vIyXQnFNsY0kaDFuKQizKNPAuVZ0QkQDwlIg8Bvwi8KSq/omI3A/cD/y+iOwH7gEOAB3AEyKyp5xze3ePJ5hMB+GnCZwpcFKFW4PTouikjC/SYNiqFDKvtwIT+Y+B/EuBu4G78uUPAT8Efj9f/rCqpoGzInIauB14upgVL5TXLrcT/1YN8SlF1DSXDQbD6imoM0dEbBE5AvQDj6vqs0CrqvYC5P+35BfvBC7OWb07X7bhHOtvRV+PE0gqy3RgGwwGw7IU1JmTbzYfEpEE8DURObjM4osNL18gUyJyL3AvQKS1sADv1fBKdyd134sSnDRWpMFgWB+rCg9S1RH8JvYHgD4RaQfI/+/PL9YNbJuzWhfQs8i2HlTVW1X11lAisvqaL4Gnwqs9HSS+EyU4acxIg8GwflYUShFpzluSiEgEeA9wHHgU+ER+sU8AX8+/fxS4R0RCIrIT2A08V+R6L8nRnnbqvh1bEBtpMBgMa6WQpnc78JCI2PjC+oiqflNEngYeEZFPAheAXwFQ1ddE5BHgdSAH3FfqHu+cZ3NlKkb/UC2JxyNGJA0GQ8G4AfCc5RNSFtLr/QpweJHyQeDdS6zzAPBAYdVcO54KF8fqGXmtkaYjSrOCeEYkDQbD8iSbLcbvTNL8zTDpOotM3fLLb9qROScGWkgfr6PuJLQYX6TBsOWYahCsHITGFt7/bhCmmi1qLi3emRsa9dCno4jrER3wiA4sv69NJ5SjmQgXf9JF/CzUGoE0GLYsY9cpTlKwzghOSpE5mqgiLJKqYQY7A7G+wiNiNo1QeiocOXMNsddCNFzwTFykwbDFaXkeUGXwRqH2tMyLcnHSSu2F4onEphBKT4WXXttJ61MWdtbERRoMBmYsyKaXS281VbxQ5jybl49fQ9uPLaxcuWtjMBi2IhUtlOdHGxg+3kD788zzPxgMBsNGUrFCmXID5B5rovWKUUiDwVBeKjLDec6zee1kF+FhI5IGg6H8VKRFeWE0QdsPbKyyZbA0GAyGWSrSolQVI5IGg6FiqEihHD9ZX+4qGAxVixsArcg7v3KpyNMV61l+gLrBYFg7QweF/lvLXYvNRUX6KA0GQ+loOqJMtlmA6SwtlIqzKI9faSU4asYnGgylQhRqeo1IroaKE8rJoQjBCSOUBoOhcqg4oWxqGyOVMD5Kg8FQOVScUA5criU8YixKg8FQOVScUBoMBkOlUVFCmXID1B4NlrsaBoPBMI+KEsqsaxMeMs1ug8FQWVSUUL7x4jbstBFKg8FQWVSMUHaPJ0icxEzxYDAYKo4VhVJEwiLynIi8LCKvicgf5cv/UEQuiciR/OuDc9b5tIicFpETIvL+QiqSzAQImUBzg8FQgRQyhDENvEtVJ0QkADwlIo/lv/sLVf3zuQuLyH7gHuAA0AE8ISJ7VHXZfEDjQzHiq6+/wWAwlJwVLUr1mch/DORfy5l+dwMPq2paVc8Cp4HbV9pP7cumt9tgMFQmBfkoRcQWkSNAP/C4qj6b/+pTIvKKiHxRRKZzo3UCF+es3p0vu3qb94rI8yLy/ORQmoCZo9tgMFQoBQmlqrqqegjoAm4XkYPA54FdwCGgF/hMfvHFxh8uUEFVfVBVb1XVWwNaS2jMCKXBYKhMVtXrraojwA+BD6hqX15APeCvmW1edwPb5qzWBfQst10x2cwNBkMFU0ivd7OIJPLvI8B7gOMi0j5nsY8AR/PvHwXuEZGQiOwEdgPPFbXWBoPBsIEU0uvdDjwkIja+sD6iqt8Ukb8VkUP4zepzwG8AqOprIvII8DqQA+5bqcfbYDAYKpkVhVJVXwEOL1L+a8us8wDwwPqqZjAYDJWBqJa/E0VErgCTwEC567KBNGGOt9rZase82Y93u6o2L/ZFRQglgIg8r6pbZsojc7zVz1Y75mo+3ooZ620wGAyVihFKg8FgWIFKEsoHy12BDcYcb/Wz1Y65ao+3YnyUBoPBUKlUkkVpMBgMFUnZhVJEPpDPW3laRO4vd32KRT5RSL+IHJ1T1iAij4vIqfz/+jnfrTqHZyUhIttE5Aciciyft/S38uVVeczL5GmtyuOdJp8g5yUR+Wb+c1Uf7wyqWrYXYANvANcCQeBlYH8561TEY3s7cDNwdE7Z/w3cn39/P/Cn+ff788ceAnbmz4ld7mNY5fG2Azfn38eBk/njqspjxk/+UpN/HwCeBe6o1uOdc9y/A/w98M3856o+3ulXuS3K24HTqnpGVTPAw/j5LDc9qvojYOiq4ruBh/LvHwJ+YU75qnN4VhKq2quqL+bfjwPH8NPrVeUxq89ieVqr8ngBRKQL+BDwX+YUV+3xzqXcQllQ7soqolVVe8EXFqAlX15V50FEduAPe32WKj7mJfK0Vu3xAn8J/B7gzSmr5uOdodxCWVDuyi1A1ZwHEakB/hH4bVUdW27RRco21THr4nlal2JTH6+I/DzQr6ovFLrKImWb5nivptxCuerclZucvun0dPn//fnyqjgP+TmV/hH4kqp+NV9c1ccM8/O0Ur3Heyfwz0TkHL6L7F0i8ndU7/HOo9xC+TNgt4jsFJEg/qRkj5a5TqXkUeAT+fefAL4+p3xT5/AUEQG+ABxT1c/O+aoqj3mpPK1U6fGq6qdVtUtVd+Dfp99X1X9OlR7vAsrdmwR8EL+H9A3g35e7PkU8ri/jT5GRxX+6fhJoBJ4ETuX/N8xZ/t/nz8EJ4OfKXf81HO9b8ZtWrwBH8q8PVusxAzcCL+WP9yjwf+TLq/J4rzr2u5jt9a7641VVMzLHYDAYVqLcTW+DwWCoeIxQGgwGwwoYoTQYDIYVMEJpMBgMK2CE0mAwGFbACKXBYDCsgBFKg8FgWAEjlAaDwbAC/z85l7Oo8p/QPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(plt.imread(glob.glob('./data/CamVidDataset/train/labels/*')[i], format='png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found or incomplete. Please make sure all required folders for the specified \"split\" and \"mode\" are inside the \"root\" directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a844349125b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Download train and test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCityscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# test_dataset = datasets.Cityscapes(root='./data', train=False,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                                  download=True, transform=transform)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/torchvision/datasets/cityscapes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, mode, target_type, transform, target_transform, transforms)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_dir_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 raise RuntimeError('Dataset not found or incomplete. Please make sure all required folders for the'\n\u001b[0m\u001b[1;32m    154\u001b[0m                                    ' specified \"split\" and \"mode\" are inside the \"root\" directory')\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found or incomplete. Please make sure all required folders for the specified \"split\" and \"mode\" are inside the \"root\" directory"
     ]
    }
   ],
   "source": [
    "# Download train and test dataset\n",
    "train_dataset = datasets.Cityscapes(root='./data', split='train')\n",
    "# test_dataset = datasets.Cityscapes(root='./data', train=False, \n",
    "#                                  download=True, transform=transform)\n",
    "\n",
    "# # Dataset sampler (shuffle, distributed loading)\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "#                                            shuffle=True, num_workers=num_workers)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, \n",
    "#                                           shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# print(f\"num. examples: train = {len(train_dataset)}, test = {len(test_dataset)}\")\n",
    "\n",
    "# classes = np.array(['plane', 'car', 'bird', 'cat', 'deer',\n",
    "#                     'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "# num_classes = len(classes)\n",
    "\n",
    "# # Functions to show an image\n",
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.figure(figsize=(15,10))\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.show()\n",
    "\n",
    "# # get some random training images\n",
    "# images, labels = next(iter(train_loader))\n",
    "\n",
    "# # show images\n",
    "# imshow(torchvision.utils.make_grid(images, pad_value=1))\n",
    "# print(classes[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=define></a>\n",
    "## 2. Define the CNN model **+ training step + loss + optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define the conv. blocks of UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            DoubleConvBlock(in_ch, out_ch)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(in_ch, in_ch // 2,\n",
    "                                           kernel_size=2, stride=2)\n",
    "        self.block = double_conv_block(in_ch, out_ch)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.upsample(x1)\n",
    "        # Pad\n",
    "        diff_h = x2.shape[2] - x1.shape[2]\n",
    "        diff_w = x2.shape[3] - x1.shape[3]\n",
    "        x1 = F.pad(x1, [diff_w//2, diff_w - diff_w//2, diff_h//2, diff_h-diff_h//2])\n",
    "        # Concatenate + conv\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.block(x)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define the U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(pl.LightningModule):\n",
    "    def __init__(self, num_classes, num_input_features=3, num_layers=5, base_features=32, **kwargs):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # save hyper-parameters\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Encoder blocks\n",
    "        features = self.hparams.base_features * (2 ** np.arange(self.hparams.num_layers))\n",
    "        setattr(self, f'encoder_block{0}', DoubleConvBlock(self.hparams.num_input_features, features[0]))\n",
    "        for i, (in_ch, out_ch) in enumerate(zip(features[:-1], features[1:])):\n",
    "            setattr(self, f'encoder_block{i+1}', Encoder(in_ch, out_ch))\n",
    "        \n",
    "        # Decoder blocks\n",
    "        for i, (in_ch, out_ch) in enumerate(zip(features[::-1], features[::-1][1:])):\n",
    "            setattr(self, f'decoder_block{self.hparams.num_layers-1-i}', Decoder(in_ch, out_ch))\n",
    "            \n",
    "        # Output layer\n",
    "        setattr(self, f'decoder_block{0}', nn.Conv2d(features[0], self.hparams.num_classes, kernel_size=1))\n",
    "      \n",
    "        self.example_input_array = torch.ones(1, self.hparams.num_input_features, 64, 64)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        xi = [x]\n",
    "        # Encoding\n",
    "        for i in range(self.hparams.num_layers):#self.blocks[1:self.hparams.num_layers]:\n",
    "            xi.append(getattr(self, f'encoder_block{i}')(xi[-1]))\n",
    "        # Decoding\n",
    "        for i in reversed(range(1, self.hparams.num_layers)):\n",
    "            xi[-1] = getattr(self, f'decoder_block{i}')(xi[-1], xi[i-self.hparams.num_layers-1])\n",
    "        return self.decoder_block0(xi[-1])\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x_train, y_train = batch\n",
    "        y_pred = self(x_train)\n",
    "        if self.num_classes > 1:\n",
    "            loss = F.cross_entropy(y_pred, y_train)\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y_train)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True) # logging\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.1)\n",
    "    \n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         x_test, y_test = batch\n",
    "#         y_pred = self(x_test)\n",
    "#         loss = F.cross_entropy(y_pred, y_test) # loss\n",
    "#         self.log('val_loss', loss)\n",
    "        \n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         x_test, y_test = batch\n",
    "#         y_pred = self(x_test)\n",
    "#         loss = F.cross_entropy(y_pred, y_test)\n",
    "#         self.log('test_loss', loss)\n",
    "    \n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.SGD(self.parameters(),\n",
    "#                                lr=self.hparams.learning_rate,\n",
    "#                                momentum=self.hparams.momentum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "model = UNet(num_classes=1, num_input_features=3, num_layers=5, base_features=32)\n",
    "model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd47075ff10>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model(torch.ones(1,3, 32, 32)).detach().numpy()[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=trainer></a>\n",
    "## 3. Setup the **trainer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define a logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = pl.loggers.TensorBoardLogger(save_dir=\"lightning_logs\", \n",
    "#                                       name=\"CIFAR10\",\n",
    "#                                       log_graph=True)\n",
    "\n",
    "# # Further loggers: https://pytorch-lightning.readthedocs.io/en/latest/logging.html\n",
    "# # Commet.ml, CSV, MLflow, Neptune, Tensorboard, TestTube, WandB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Early stopping\n",
    "# early_stopping_callback = pl.callbacks.early_stopping.EarlyStopping(monitor='val_loss')\n",
    "\n",
    "# # checkpoint\n",
    "# checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "#     monitor='val_loss',\n",
    "#     save_top_k=3,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Initialize the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 1 batch(es).\n"
     ]
    }
   ],
   "source": [
    "# GPU trainer\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=1, # num_epochs,\n",
    "    fast_dev_run=True,\n",
    "    #logger=logger,\n",
    "#     callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "#     precision=16, # half-precision\n",
    ")\n",
    "# Further trainer options: https://pytorch-lightning.readthedocs.io/en/latest/trainer.html\n",
    "# Callbacks, multi-gpu, distributed, tune lr and/or batch size, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=train></a>\n",
    "## 4. Train **and validate** the model on **train** and **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type            | Params | In sizes                            | Out sizes       \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "0 | encoder_block0 | DoubleConvBlock | 10.3 K | [1, 3, 64, 64]                      | [1, 32, 64, 64] \n",
      "1 | encoder_block1 | Encoder         | 55.7 K | [1, 32, 64, 64]                     | [1, 64, 32, 32] \n",
      "2 | encoder_block2 | Encoder         | 221 K  | [1, 64, 32, 32]                     | [1, 128, 16, 16]\n",
      "3 | encoder_block3 | Encoder         | 886 K  | [1, 128, 16, 16]                    | [1, 256, 8, 8]  \n",
      "4 | encoder_block4 | Encoder         | 3.5 M  | [1, 256, 8, 8]                      | [1, 512, 4, 4]  \n",
      "5 | decoder_block4 | Decoder         | 2.3 M  | [[1, 512, 4, 4], [1, 256, 8, 8]]    | [1, 256, 8, 8]  \n",
      "6 | decoder_block3 | Decoder         | 574 K  | [[1, 256, 8, 8], [1, 128, 16, 16]]  | [1, 128, 16, 16]\n",
      "7 | decoder_block2 | Decoder         | 143 K  | [[1, 128, 16, 16], [1, 64, 32, 32]] | [1, 64, 32, 32] \n",
      "8 | decoder_block1 | Decoder         | 36.1 K | [[1, 64, 32, 32], [1, 32, 64, 64]]  | [1, 32, 64, 64] \n",
      "9 | decoder_block0 | Conv2d          | 33     | [1, 32, 64, 64]                     | [1, 1, 64, 64]  \n",
      "------------------------------------------------------------------------------------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e104a1913a14baa84b7904971d830a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleAttributeError",
     "evalue": "'UNet' object has no attribute 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-277-d074335f320b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         model_ref.optimizer_step(\n\u001b[0m\u001b[1;32m    507\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \"\"\"\n\u001b[0;32m-> 1253\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m     def optimizer_zero_grad(\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, make_optimizer_step, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;31m# make sure to call optimizer_closure when accumulating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0maccelerator_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                             result = self.training_step_and_backward(\n\u001b[0m\u001b[1;32m    722\u001b[0m                                 \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                                 \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step_and_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# lightning module hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training_step'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_logged_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, model_step, args)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-272-e73c5b5edf56>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_nb)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'UNet' object has no attribute 'num_classes'"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=tensorboard></a>\n",
    "## 5. Assess training with **tensorboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_0\n"
     ]
    }
   ],
   "source": [
    "# Automatic logging\n",
    "!ls lightning_logs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23781), started 1:41:05 ago. (Use '!kill 23781' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-43c7520f5783b05f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-43c7520f5783b05f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"validate\"></a>\n",
    "## 5. Test the model on **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lento/lib/miniconda3/envs/ml-tutorials/lib/python3.8/site-packages/torch/jit/_trace.py:958: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "With rtol=1e-05 and atol=0.001, found 3 element(s) (out of 10) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.001953125 (3.025390625 vs. 3.0234375), which occurred at index (0, 5).\n",
      "  _check_trace(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875fe5b0438e440b86663dc0e926d0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(2.0407, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 2.040663242340088}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = next(iter(test_loader))\n",
    "\n",
    "# # predict\n",
    "# prediction = model(images.to(device))\n",
    "# prediction = prediction.cpu() # gpu -> cpu\n",
    "# predicted_labels = torch.argmax(prediction, 1).detach()\n",
    "\n",
    "# # print images\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "# print(\"Ground truth:\", classes[labels])\n",
    "# print(\"Prediction  :\", classes[predicted_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Accuracy of the model on **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in tqdm(test_loader, total=len(test_loader)):\n",
    "#         prediction = model(images.to(device)).cpu()\n",
    "#         predicted_labels = torch.argmax(prediction, 1)\n",
    "#         total += predicted_labels.size(0)\n",
    "#         correct += (predicted_labels == labels).sum().item()\n",
    "\n",
    "# print('Accuracy on {} test images: {}%'.format(\n",
    "#     len(test_loader)*batch_size,\n",
    "#      100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Accuracy of the model per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_correct = np.zeros(len(classes))\n",
    "# class_total = np.zeros(len(classes))\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in tqdm(test_loader, total=len(test_loader)):\n",
    "#         prediction = model(images.to(device)).cpu()\n",
    "#         predicted_labels = torch.argmax(prediction, 1)\n",
    "#         c = (predicted_labels == labels).squeeze()\n",
    "#         for i in range(len(labels)):\n",
    "#             label = labels[i]\n",
    "#             class_correct[label] += c[i].item()\n",
    "#             class_total[label] += 1\n",
    "\n",
    "# sorted_idx = np.argsort(class_correct/class_total)[::-1]\n",
    "# for i in sorted_idx:\n",
    "#     print('Accuracy of {:5s}: {}%'.format(\n",
    "#            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
